#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Advanced Duplicate Detection System
ìŠ¤í† ì–´ ë¦¬ì  ë°©ì§€ë¥¼ ìœ„í•œ ê³ ê¸‰ ì¤‘ë³µ íƒì§€ ì‹œìŠ¤í…œ
"""

import re
import json
import hashlib
from typing import Dict, List, Tuple, Optional
from datetime import datetime
from difflib import SequenceMatcher
from pathlib import Path
import logging

class AdvancedDuplicateDetector:
    """ê³ ê¸‰ ì¤‘ë³µ íƒì§€ ì‹œìŠ¤í…œ"""

    def __init__(self, db_path: str = "automation/app_fingerprints.json"):
        self.db_path = Path(db_path)
        self.db_path.parent.mkdir(exist_ok=True)

        self.fingerprint_db = self._load_fingerprint_db()
        self.logger = logging.getLogger(__name__)

        # ì¤‘ë³µ ì„ê³„ê°’ ì„¤ì •
        self.thresholds = {
            "name_similarity": 0.80,      # ì´ë¦„ ìœ ì‚¬ë„
            "description_similarity": 0.75, # ì„¤ëª… ìœ ì‚¬ë„
            "keyword_overlap": 0.70,       # í‚¤ì›Œë“œ ê²¹ì¹¨ë¥ 
            "feature_similarity": 0.65,    # ê¸°ëŠ¥ ìœ ì‚¬ë„
            "critical_risk": 0.85,         # ìœ„í—˜ ìˆ˜ì¤€
            "warning_risk": 0.70          # ê²½ê³  ìˆ˜ì¤€
        }

    def _load_fingerprint_db(self) -> Dict:
        """í•‘ê±°í”„ë¦°íŠ¸ DB ë¡œë“œ"""
        if self.db_path.exists():
            try:
                with open(self.db_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                self.logger.warning(f"DB ë¡œë“œ ì‹¤íŒ¨: {e}")

        return {"apps": {}, "metadata": {"created": datetime.now().isoformat()}}

    def _save_fingerprint_db(self):
        """í•‘ê±°í”„ë¦°íŠ¸ DB ì €ì¥"""
        try:
            self.fingerprint_db["metadata"]["last_updated"] = datetime.now().isoformat()
            with open(self.db_path, 'w', encoding='utf-8') as f:
                json.dump(self.fingerprint_db, f, indent=2, ensure_ascii=False)
        except Exception as e:
            self.logger.error(f"DB ì €ì¥ ì‹¤íŒ¨: {e}")

    def create_app_fingerprint(self, app_data: Dict) -> Dict:
        """ì•± í•‘ê±°í”„ë¦°íŠ¸ ìƒì„±"""

        name = app_data.get("app_name", "").lower().strip()
        description = app_data.get("description", "").lower().strip()
        features = app_data.get("core_features", [])
        category = app_data.get("category", "").lower()

        # í…ìŠ¤íŠ¸ ì •ê·œí™”
        normalized_name = self._normalize_text(name)
        normalized_desc = self._normalize_text(description)

        # í‚¤ì›Œë“œ ì¶”ì¶œ
        name_keywords = self._extract_keywords(normalized_name)
        desc_keywords = self._extract_keywords(normalized_desc)

        # ê¸°ëŠ¥ í•´ì‹œ
        feature_signatures = [self._normalize_text(f) for f in features]

        fingerprint = {
            "app_id": app_data.get("app_name", "unknown"),
            "created_at": datetime.now().isoformat(),

            # ì›ë³¸ ë°ì´í„°
            "raw_name": name,
            "raw_description": description,

            # ì •ê·œí™”ëœ ë°ì´í„°
            "normalized_name": normalized_name,
            "normalized_description": normalized_desc,

            # í‚¤ì›Œë“œ ì„¸íŠ¸
            "name_keywords": sorted(name_keywords),
            "desc_keywords": sorted(desc_keywords),
            "all_keywords": sorted(name_keywords | desc_keywords),

            # ê¸°ëŠ¥ ì‹œê·¸ë‹ˆì²˜
            "feature_signatures": sorted(feature_signatures),
            "category": category,

            # í•´ì‹œê°’ë“¤
            "name_hash": hashlib.md5(normalized_name.encode()).hexdigest(),
            "desc_hash": hashlib.md5(normalized_desc.strip().encode()).hexdigest(),
            "combined_hash": hashlib.md5(f"{normalized_name}|{normalized_desc}".encode()).hexdigest(),

            # ë©”íƒ€ë°ì´í„°
            "generation_cost": app_data.get("total_cost", 0),
            "quality_score": app_data.get("quality_score", 0)
        }

        return fingerprint

    def detect_duplicates(self, new_app_data: Dict) -> Dict:
        """ì¤‘ë³µ íƒì§€ ë° ìœ„í—˜ í‰ê°€"""

        new_fingerprint = self.create_app_fingerprint(new_app_data)
        existing_apps = self.fingerprint_db.get("apps", {})

        if not existing_apps:
            return {
                "is_duplicate": False,
                "risk_level": "low",
                "risk_score": 0.0,
                "matches": [],
                "recommendations": ["ì²« ë²ˆì§¸ ì•±ì´ë¯€ë¡œ ì¤‘ë³µ ìœ„í—˜ ì—†ìŒ"]
            }

        matches = []
        max_risk_score = 0.0

        for app_id, existing_fp in existing_apps.items():
            match_result = self._compare_fingerprints(new_fingerprint, existing_fp)

            if match_result["total_similarity"] > self.thresholds["warning_risk"]:
                matches.append({
                    "app_id": app_id,
                    "similarity_score": match_result["total_similarity"],
                    "similar_aspects": match_result["similar_aspects"],
                    "details": match_result
                })

                max_risk_score = max(max_risk_score, match_result["total_similarity"])

        # ìœ„í—˜ ìˆ˜ì¤€ ê²°ì •
        if max_risk_score >= self.thresholds["critical_risk"]:
            risk_level = "critical"
            is_duplicate = True
        elif max_risk_score >= self.thresholds["warning_risk"]:
            risk_level = "warning"
            is_duplicate = False
        else:
            risk_level = "low"
            is_duplicate = False

        # ê¶Œì¥ì‚¬í•­ ìƒì„±
        recommendations = self._generate_recommendations(matches, new_fingerprint)

        return {
            "is_duplicate": is_duplicate,
            "risk_level": risk_level,
            "risk_score": max_risk_score,
            "matches": sorted(matches, key=lambda x: x["similarity_score"], reverse=True),
            "recommendations": recommendations,
            "fingerprint": new_fingerprint
        }

    def _compare_fingerprints(self, fp1: Dict, fp2: Dict) -> Dict:
        """ë‘ í•‘ê±°í”„ë¦°íŠ¸ ë¹„êµ"""

        # 1. ì´ë¦„ ìœ ì‚¬ë„
        name_sim = self._text_similarity(fp1["normalized_name"], fp2["normalized_name"])

        # 2. ì„¤ëª… ìœ ì‚¬ë„
        desc_sim = self._text_similarity(fp1["normalized_description"], fp2["normalized_description"])

        # 3. í‚¤ì›Œë“œ ê²¹ì¹¨ë¥ 
        keyword_overlap = self._set_overlap(
            set(fp1["all_keywords"]),
            set(fp2["all_keywords"])
        )

        # 4. ê¸°ëŠ¥ ìœ ì‚¬ë„
        feature_sim = self._feature_similarity(
            fp1["feature_signatures"],
            fp2["feature_signatures"]
        )

        # 5. ì¹´í…Œê³ ë¦¬ ì¼ì¹˜
        category_match = 1.0 if fp1["category"] == fp2["category"] else 0.0

        # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ì´ ìœ ì‚¬ë„ ê³„ì‚°
        weights = {
            "name": 0.30,
            "description": 0.25,
            "keywords": 0.20,
            "features": 0.15,
            "category": 0.10
        }

        total_similarity = (
            name_sim * weights["name"] +
            desc_sim * weights["description"] +
            keyword_overlap * weights["keywords"] +
            feature_sim * weights["features"] +
            category_match * weights["category"]
        )

        # ìœ ì‚¬í•œ ì¸¡ë©´ë“¤ ì‹ë³„
        similar_aspects = []
        if name_sim > 0.8:
            similar_aspects.append("name")
        if desc_sim > 0.7:
            similar_aspects.append("description")
        if keyword_overlap > 0.7:
            similar_aspects.append("keywords")
        if feature_sim > 0.6:
            similar_aspects.append("features")
        if category_match > 0:
            similar_aspects.append("category")

        return {
            "total_similarity": total_similarity,
            "name_similarity": name_sim,
            "description_similarity": desc_sim,
            "keyword_overlap": keyword_overlap,
            "feature_similarity": feature_sim,
            "category_match": category_match,
            "similar_aspects": similar_aspects
        }

    def _normalize_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì •ê·œí™”"""
        if not text:
            return ""

        # ì†Œë¬¸ì ë³€í™˜
        text = text.lower()

        # íŠ¹ìˆ˜ë¬¸ì ì œê±° (ê³µë°±ì€ ìœ ì§€)
        text = re.sub(r'[^\w\sê°€-í£]', ' ', text)

        # ì—°ì† ê³µë°± ì œê±°
        text = re.sub(r'\s+', ' ', text)

        # ê³µí†µ ë‹¨ì–´ ì œê±° (ë„ˆë¬´ ì¼ë°˜ì ì¸ ë‹¨ì–´ë“¤)
        common_words = {
            'app', 'pro', 'premium', 'best', 'top', 'smart', 'super',
            'advanced', 'ultimate', 'perfect', 'amazing', 'incredible',
            'ì•±', 'í”„ë¡œ', 'í”„ë¦¬ë¯¸ì—„', 'ìµœê³ ', 'ìŠ¤ë§ˆíŠ¸', 'ê³ ê¸‰', 'ì™„ë²½'
        }

        words = text.split()
        filtered_words = [w for w in words if w not in common_words and len(w) > 2]

        return ' '.join(filtered_words).strip()

    def _extract_keywords(self, text: str) -> set:
        """í‚¤ì›Œë“œ ì¶”ì¶œ"""
        if not text:
            return set()

        # ë‹¨ì–´ ë¶„í• 
        words = re.findall(r'\b\w{3,}\b', text)

        # ì˜ë¯¸ìˆëŠ” í‚¤ì›Œë“œë§Œ ì¶”ì¶œ (ê¸¸ì´ 3ì ì´ìƒ)
        keywords = {word.lower() for word in words if len(word) >= 3}

        return keywords

    def _text_similarity(self, text1: str, text2: str) -> float:
        """í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê³„ì‚°"""
        if not text1 or not text2:
            return 0.0

        return SequenceMatcher(None, text1, text2).ratio()

    def _set_overlap(self, set1: set, set2: set) -> float:
        """ì§‘í•© ê²¹ì¹¨ë¥  ê³„ì‚°"""
        if not set1 or not set2:
            return 0.0

        intersection = len(set1 & set2)
        union = len(set1 | set2)

        return intersection / union if union > 0 else 0.0

    def _feature_similarity(self, features1: List[str], features2: List[str]) -> float:
        """ê¸°ëŠ¥ ìœ ì‚¬ë„ ê³„ì‚°"""
        if not features1 or not features2:
            return 0.0

        # ê° ê¸°ëŠ¥ì„ í‚¤ì›Œë“œ ì„¸íŠ¸ë¡œ ë³€í™˜
        f1_keywords = set()
        f2_keywords = set()

        for f in features1:
            f1_keywords.update(self._extract_keywords(f))

        for f in features2:
            f2_keywords.update(self._extract_keywords(f))

        return self._set_overlap(f1_keywords, f2_keywords)

    def _generate_recommendations(self, matches: List[Dict], new_fp: Dict) -> List[str]:
        """ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []

        if not matches:
            recommendations.append("âœ… ì¤‘ë³µ ìœ„í—˜ì´ ë‚®ìŠµë‹ˆë‹¤. ì•ˆì „í•˜ê²Œ ì§„í–‰ ê°€ëŠ¥")
            return recommendations

        highest_match = matches[0]
        similarity = highest_match["similarity_score"]
        similar_aspects = highest_match["similar_aspects"]

        if similarity >= self.thresholds["critical_risk"]:
            recommendations.append("ğŸš¨ ë†’ì€ ì¤‘ë³µ ìœ„í—˜! ë‹¤ìŒì„ ìˆ˜ì •í•˜ì„¸ìš”:")

            if "name" in similar_aspects:
                recommendations.append("  â€¢ ì•± ì´ë¦„ì„ ì™„ì „íˆ ë‹¤ë¥´ê²Œ ë³€ê²½")

            if "description" in similar_aspects:
                recommendations.append("  â€¢ ì•± ì„¤ëª…ì„ ìƒˆë¡œ ì‘ì„± (50% ì´ìƒ ë³€ê²½)")

            if "keywords" in similar_aspects:
                recommendations.append("  â€¢ í‚¤ì›Œë“œ 3ê°œ ì´ìƒ êµì²´")

            if "features" in similar_aspects:
                recommendations.append("  â€¢ í•µì‹¬ ê¸°ëŠ¥ 2ê°œ ì´ìƒ ì°¨ë³„í™”")

        elif similarity >= self.thresholds["warning_risk"]:
            recommendations.append("âš ï¸ ì¤‘ê°„ ìœ„í—˜ë„. ë‹¤ìŒ ê°œì„  ê¶Œì¥:")

            if "name" in similar_aspects:
                recommendations.append("  â€¢ ì•± ì´ë¦„ì— ê³ ìœ  ìˆ˜ì‹ì–´ ì¶”ê°€")

            if "description" in similar_aspects:
                recommendations.append("  â€¢ ì„¤ëª… ì²« ë¬¸ì¥ì„ ë‹¤ë¥´ê²Œ ì‘ì„±")

            recommendations.append("  â€¢ ì°¨ë³„í™” í¬ì¸íŠ¸ 3ê°œ ì´ìƒ ê°•ì¡°")

        # ì¼ë°˜ì ì¸ ê°œì„  ì œì•ˆ
        if len(new_fp["all_keywords"]) < 5:
            recommendations.append("ğŸ’¡ í‚¤ì›Œë“œê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. 5ê°œ ì´ìƒ ê¶Œì¥")

        return recommendations

    def add_app_to_db(self, app_data: Dict) -> bool:
        """ì•±ì„ DBì— ì¶”ê°€"""
        try:
            fingerprint = self.create_app_fingerprint(app_data)
            app_id = fingerprint["app_id"]

            self.fingerprint_db["apps"][app_id] = fingerprint
            self._save_fingerprint_db()

            self.logger.info(f"ì•± '{app_id}' í•‘ê±°í”„ë¦°íŠ¸ê°€ DBì— ì¶”ê°€ë¨")
            return True

        except Exception as e:
            self.logger.error(f"DB ì¶”ê°€ ì‹¤íŒ¨: {e}")
            return False

    def generate_duplicate_report(self, app_data: Dict) -> str:
        """ì¤‘ë³µ íƒì§€ ë¦¬í¬íŠ¸ ìƒì„±"""

        result = self.detect_duplicates(app_data)

        report = f"""
ğŸ” ì¤‘ë³µ íƒì§€ ë¦¬í¬íŠ¸
{'='*50}

ì•± ì´ë¦„: {app_data.get('app_name', 'N/A')}
ê²€ì‚¬ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

ğŸ“Š ì¢…í•© í‰ê°€:
  ìœ„í—˜ ìˆ˜ì¤€: {result['risk_level'].upper()}
  ìœ ì‚¬ë„ ì ìˆ˜: {result['risk_score']:.2%}
  ì¤‘ë³µ íŒì •: {'ì˜ˆ' if result['is_duplicate'] else 'ì•„ë‹ˆì˜¤'}

"""

        if result["matches"]:
            report += "âš ï¸ ìœ ì‚¬í•œ ì•±ë“¤:\n"
            for match in result["matches"][:3]:  # ìƒìœ„ 3ê°œë§Œ
                report += f"  â€¢ {match['app_id']}: {match['similarity_score']:.1%} ìœ ì‚¬\n"
                report += f"    ìœ ì‚¬ ì¸¡ë©´: {', '.join(match['similar_aspects'])}\n"

        report += "\nğŸ’¡ ê¶Œì¥ì‚¬í•­:\n"
        for rec in result["recommendations"]:
            report += f"  {rec}\n"

        return report

    def get_db_stats(self) -> Dict:
        """DB í†µê³„ ì •ë³´"""
        apps = self.fingerprint_db.get("apps", {})

        if not apps:
            return {"total_apps": 0, "categories": {}, "avg_quality": 0}

        categories = {}
        total_quality = 0

        for app_data in apps.values():
            cat = app_data.get("category", "unknown")
            categories[cat] = categories.get(cat, 0) + 1
            total_quality += app_data.get("quality_score", 0)

        return {
            "total_apps": len(apps),
            "categories": categories,
            "avg_quality": total_quality / len(apps) if apps else 0,
            "last_updated": self.fingerprint_db.get("metadata", {}).get("last_updated", "N/A")
        }

def main():
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    detector = AdvancedDuplicateDetector()

    # í…ŒìŠ¤íŠ¸ ì•± 1
    test_app1 = {
        "app_name": "Premium Fitness Tracker Pro",
        "description": "Advanced fitness tracking app with workout monitoring, nutrition logging, and health analytics for professional athletes and fitness enthusiasts.",
        "core_features": ["Workout tracking", "Nutrition logging", "Health analytics", "Social sharing"],
        "category": "fitness",
        "total_cost": 0.665,
        "quality_score": 87
    }

    # í…ŒìŠ¤íŠ¸ ì•± 2 (ìœ ì‚¬í•¨)
    test_app2 = {
        "app_name": "Elite Fitness Monitor",
        "description": "Professional fitness monitoring application with advanced workout tracking, meal planning, and comprehensive health analytics.",
        "core_features": ["Exercise monitoring", "Meal planning", "Health statistics", "Progress sharing"],
        "category": "fitness",
        "total_cost": 0.665,
        "quality_score": 85
    }

    print("=== ì²« ë²ˆì§¸ ì•± ë“±ë¡ ===")
    detector.add_app_to_db(test_app1)

    print("\n=== ë‘ ë²ˆì§¸ ì•± ì¤‘ë³µ ê²€ì‚¬ ===")
    report = detector.generate_duplicate_report(test_app2)
    print(report)

    print("\n=== DB í†µê³„ ===")
    stats = detector.get_db_stats()
    print(f"ì´ ì•± ìˆ˜: {stats['total_apps']}")
    print(f"ì¹´í…Œê³ ë¦¬: {stats['categories']}")
    print(f"í‰ê·  í’ˆì§ˆ: {stats['avg_quality']:.1f}")

if __name__ == "__main__":
    main()