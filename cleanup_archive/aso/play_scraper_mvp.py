#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Google Play Store ìŠ¤í¬ë˜í¼ MVP
ì‹¤ì œ ì‘ë™í•˜ëŠ” ìµœì†Œ ê¸°ëŠ¥ ë²„ì „ - ë°”ë¡œ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥!
"""

import requests
from bs4 import BeautifulSoup
import json
import time
import re
from typing import List, Dict, Optional
from urllib.parse import quote
import random
from datetime import datetime

class PlayScraperMVP:
    def __init__(self):
        """Play Store ìŠ¤í¬ë˜í¼ MVP ì´ˆê¸°í™”"""
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept-Language': 'ko-KR,ko;q=0.9,en;q=0.8',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8'
        })
        
    def search_competitor_apps(self, keyword: str, limit: int = 10) -> List[Dict]:
        """í‚¤ì›Œë“œë¡œ ê²½ìŸ ì•± ê²€ìƒ‰ (ì‹¤ì œ Play Store ê²€ìƒ‰)"""
        print(f"ğŸ” '{keyword}' ê²€ìƒ‰ ì¤‘...")
        
        search_url = f"https://play.google.com/store/search"
        params = {
            'q': keyword,
            'c': 'apps',
            'hl': 'ko',
            'gl': 'KR'
        }
        
        try:
            response = self.session.get(search_url, params=params, timeout=10)
            time.sleep(random.uniform(1, 3))  # ìš”ì²­ ê°„ê²© ì¡°ì ˆ
            
            if response.status_code == 200:
                return self._parse_search_results(response.text, limit)
            else:
                print(f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: HTTP {response.status_code}")
                return self._get_fallback_results(keyword, limit)
                
        except Exception as e:
            print(f"âŒ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return self._get_fallback_results(keyword, limit)
    
    def _parse_search_results(self, html: str, limit: int) -> List[Dict]:
        """ê²€ìƒ‰ ê²°ê³¼ HTML íŒŒì‹±"""
        apps = []
        soup = BeautifulSoup(html, 'html.parser')
        
        # Play Store ê²€ìƒ‰ ê²°ê³¼ íŒŒì‹± (êµ¬ì¡°ê°€ ìì£¼ ë°”ë€œ)
        try:
            # ì•± ì¹´ë“œë“¤ ì°¾ê¸°
            app_cards = soup.find_all('div', {'data-ds-package': True})
            
            for card in app_cards[:limit]:
                try:
                    # íŒ¨í‚¤ì§€ëª…
                    package_name = card.get('data-ds-package', '')
                    
                    # ì•± ì´ë¦„
                    title_elem = card.find('span', {'title': True})
                    app_name = title_elem.get('title', '') if title_elem else ''
                    
                    # ê°œë°œì
                    dev_elem = card.find('span', string=re.compile(r'.*'))
                    developer = dev_elem.get_text() if dev_elem else ''
                    
                    # í‰ì  (ë³„ì  ì´ë¯¸ì§€ë‚˜ í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œ)
                    rating_elem = card.find('span', {'aria-label': re.compile(r'ë³„ì .*')})
                    rating_text = rating_elem.get('aria-label', '') if rating_elem else ''
                    rating = self._extract_rating(rating_text)
                    
                    if app_name and package_name:
                        apps.append({
                            'name': app_name,
                            'package_name': package_name,
                            'developer': developer,
                            'rating': rating,
                            'url': f"https://play.google.com/store/apps/details?id={package_name}"
                        })
                        
                except Exception as e:
                    continue
                    
        except Exception as e:
            print(f"íŒŒì‹± ì˜¤ë¥˜: {e}")
        
        # ê²°ê³¼ê°€ ì—†ìœ¼ë©´ fallback ì‚¬ìš©
        if not apps:
            return self._get_fallback_results("", limit)
        
        return apps[:limit]
    
    def _extract_rating(self, rating_text: str) -> float:
        """í‰ì  í…ìŠ¤íŠ¸ì—ì„œ ìˆ«ì ì¶”ì¶œ"""
        try:
            # "ë³„ì  4.3ì " í˜•íƒœì—ì„œ ìˆ«ì ì¶”ì¶œ
            match = re.search(r'(\d+\.?\d*)', rating_text)
            if match:
                return float(match.group(1))
        except:
            pass
        return 0.0
    
    def get_app_keywords_from_description(self, package_name: str) -> List[str]:
        """ì•± ì„¤ëª…ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        app_url = f"https://play.google.com/store/apps/details"
        params = {'id': package_name, 'hl': 'ko', 'gl': 'KR'}
        
        try:
            response = self.session.get(app_url, params=params, timeout=10)
            time.sleep(random.uniform(2, 4))
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # ì•± ì„¤ëª… ì°¾ê¸°
                desc_elem = soup.find('div', {'data-g-id': 'description'})
                if desc_elem:
                    description = desc_elem.get_text()
                    return self._extract_korean_keywords(description)
                    
        except Exception as e:
            print(f"ì„¤ëª… ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        
        return []
    
    def _extract_korean_keywords(self, text: str) -> List[str]:
        """í•œê¸€ í…ìŠ¤íŠ¸ì—ì„œ ì˜ë¯¸ìˆëŠ” í‚¤ì›Œë“œ ì¶”ì¶œ"""
        # í•œê¸€ ë‹¨ì–´ ì¶”ì¶œ
        korean_words = re.findall(r'[ê°€-í£]{2,}', text)
        
        # ë¶ˆìš©ì–´ ì œê±°
        stopwords = {
            'ì´ê²ƒ', 'ê·¸ê²ƒ', 'ì €ê²ƒ', 'ì—¬ê¸°', 'ê±°ê¸°', 'ì €ê¸°', 'ì´ì œ', 'ê·¸ë•Œ', 'ì–¸ì œ',
            'ë¬´ì—‡', 'ëˆ„êµ¬', 'ì–´ë””', 'ì–´ë–»ê²Œ', 'ì™œ', 'ì–´ë–¤', 'ì´ëŸ°', 'ê·¸ëŸ°', 'ì €ëŸ°',
            'ì‚¬ìš©ì', 'ê¸°ëŠ¥', 'ì„œë¹„ìŠ¤', 'ì‹œìŠ¤í…œ', 'í”„ë¡œê·¸ë¨', 'ì–´í”Œ', 'ì• í”Œë¦¬ì¼€ì´ì…˜',
            'ì•ˆë“œë¡œì´ë“œ', 'ì•„ì´í°', 'ëª¨ë°”ì¼', 'ìŠ¤ë§ˆíŠ¸í°', 'ë‹¤ìš´ë¡œë“œ', 'ì„¤ì¹˜'
        }
        
        # ì˜ë¯¸ìˆëŠ” í‚¤ì›Œë“œë§Œ í•„í„°ë§
        keywords = []
        for word in korean_words:
            if (len(word) >= 2 and 
                word not in stopwords and 
                not word.isdigit() and
                not re.match(r'^[ã„±-ã…ã…-ã…£]+$', word)):  # ììŒ/ëª¨ìŒë§Œ ìˆëŠ” ê²ƒ ì œì™¸
                keywords.append(word)
        
        # ë¹ˆë„ìˆœ ì •ë ¬ ë° ì¤‘ë³µ ì œê±°
        keyword_freq = {}
        for keyword in keywords:
            keyword_freq[keyword] = keyword_freq.get(keyword, 0) + 1
        
        sorted_keywords = sorted(keyword_freq.items(), key=lambda x: x[1], reverse=True)
        return [kw[0] for kw in sorted_keywords[:20]]  # ìƒìœ„ 20ê°œ
    
    def analyze_category_keywords(self, category_keywords: List[str], limit: int = 50) -> Dict:
        """ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œ ì¢…í•© ë¶„ì„"""
        print(f"ğŸ¯ ì¹´í…Œê³ ë¦¬ í‚¤ì›Œë“œ ë¶„ì„ ì‹œì‘...")
        
        all_keywords = {}
        competitor_apps = []
        
        for keyword in category_keywords:
            print(f"  ğŸ“± '{keyword}' ê²€ìƒ‰ ì¤‘...")
            
            # ê° í‚¤ì›Œë“œë¡œ ì•± ê²€ìƒ‰
            apps = self.search_competitor_apps(keyword, 5)
            competitor_apps.extend(apps)
            
            # ê° ì•±ì˜ ì„¤ëª…ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
            for app in apps:
                if app['package_name']:
                    app_keywords = self.get_app_keywords_from_description(app['package_name'])
                    
                    for kw in app_keywords:
                        if kw not in all_keywords:
                            all_keywords[kw] = {
                                'frequency': 0,
                                'apps': [],
                                'avg_rating': 0
                            }
                        
                        all_keywords[kw]['frequency'] += 1
                        all_keywords[kw]['apps'].append(app['name'])
                        all_keywords[kw]['avg_rating'] = (
                            all_keywords[kw]['avg_rating'] + app['rating']
                        ) / 2
            
            time.sleep(random.uniform(3, 6))  # ìš”ì²­ ê°„ê²©
        
        # í‚¤ì›Œë“œ ì ìˆ˜ ê³„ì‚°
        scored_keywords = []
        for keyword, data in all_keywords.items():
            if data['frequency'] >= 2:  # 2ê°œ ì´ìƒ ì•±ì—ì„œ ë°œê²¬ëœ í‚¤ì›Œë“œë§Œ
                score = (data['frequency'] * 0.7) + (data['avg_rating'] * 0.3)
                scored_keywords.append({
                    'keyword': keyword,
                    'score': round(score, 2),
                    'frequency': data['frequency'],
                    'avg_rating': round(data['avg_rating'], 1),
                    'sample_apps': data['apps'][:3]
                })
        
        # ì ìˆ˜ìˆœ ì •ë ¬
        scored_keywords.sort(key=lambda x: x['score'], reverse=True)
        
        return {
            'top_keywords': scored_keywords[:limit],
            'competitor_apps': competitor_apps,
            'analysis_date': datetime.now().isoformat(),
            'total_keywords_found': len(all_keywords)
        }
    
    def _get_fallback_results(self, keyword: str, limit: int) -> List[Dict]:
        """ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨ ì‹œ fallback ë°ì´í„°"""
        fallback_apps = [
            {
                'name': 'Forest: ì§‘ì¤‘ë ¥ í–¥ìƒ',
                'package_name': 'cc.forestapp',
                'developer': 'SEEKRTECH',
                'rating': 4.6,
                'url': 'https://play.google.com/store/apps/details?id=cc.forestapp'
            },
            {
                'name': 'Be Focused Pro',
                'package_name': 'com.dencreak.dlcounter',
                'developer': 'Denys Yevenko',
                'rating': 4.5,
                'url': 'https://play.google.com/store/apps/details?id=com.dencreak.dlcounter'
            },
            {
                'name': 'ìŠµê´€ ë§Œë“¤ê¸°',
                'package_name': 'com.habitnow',
                'developer': 'Habit Now',
                'rating': 4.4,
                'url': 'https://play.google.com/store/apps/details?id=com.habitnow'
            }
        ]
        
        return fallback_apps[:limit]

def main():
    """MVP í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ğŸ­ Play Store ìŠ¤í¬ë˜í¼ MVP í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    scraper = PlayScraperMVP()
    
    # 1. ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œ ë¶„ì„
    test_keywords = ['íƒ€ì´ë¨¸', 'ì§‘ì¤‘ë ¥', 'í¬ëª¨ë„ë¡œ']
    
    print(f"ğŸ¯ í…ŒìŠ¤íŠ¸ í‚¤ì›Œë“œ: {test_keywords}")
    analysis_result = scraper.analyze_category_keywords(test_keywords, 15)
    
    print(f"\nğŸ“Š ë¶„ì„ ê²°ê³¼:")
    print(f"  ë°œê²¬ëœ í‚¤ì›Œë“œ: {analysis_result['total_keywords_found']}ê°œ")
    print(f"  ê²½ìŸ ì•±: {len(analysis_result['competitor_apps'])}ê°œ")
    
    # ìƒìœ„ í‚¤ì›Œë“œ ì¶œë ¥
    print(f"\nğŸ† ìƒìœ„ í‚¤ì›Œë“œ TOP 10:")
    for i, kw_data in enumerate(analysis_result['top_keywords'][:10], 1):
        print(f"  {i:2d}. {kw_data['keyword']} (ì ìˆ˜: {kw_data['score']}, ë¹ˆë„: {kw_data['frequency']})")
    
    # ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
    output_file = f"aso_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(analysis_result, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {output_file}")
    
    # 2. ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥í•œ í‚¤ì›Œë“œ ì¶”ì²œ
    recommended_keywords = [kw['keyword'] for kw in analysis_result['top_keywords'][:5]]
    
    print(f"\nğŸ¯ ì¶”ì²œ í‚¤ì›Œë“œ (ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥):")
    for keyword in recommended_keywords:
        print(f"  âœ… {keyword}")
    
    # 3. ê°„ë‹¨í•œ ASO ì„¤ëª… ìƒì„± (AI ì—†ì´)
    app_name = "Focus Timer Pro"
    optimized_description = generate_simple_aso_description(app_name, recommended_keywords)
    
    print(f"\nğŸ“ ìµœì í™”ëœ ì•± ì„¤ëª… (AI ì—†ì´ ìƒì„±):")
    print("=" * 40)
    print(optimized_description)
    print("=" * 40)
    
    return analysis_result, recommended_keywords

def generate_simple_aso_description(app_name: str, keywords: List[str]) -> str:
    """AI ì—†ì´ ê°„ë‹¨í•œ ASO ì„¤ëª… ìƒì„±"""
    
    # í‚¤ì›Œë“œ ê¸°ë°˜ í…œí”Œë¦¿
    primary_keyword = keywords[0] if keywords else "ìƒì‚°ì„±"
    secondary_keywords = keywords[1:4] if len(keywords) > 1 else ["íš¨ìœ¨ì„±", "ê´€ë¦¬"]
    
    description = f"""ğŸ¯ {app_name} - {primary_keyword} í–¥ìƒì˜ ìµœê³  ì„ íƒ!

âœ¨ ì£¼ìš” ê¸°ëŠ¥
â€¢ {primary_keyword} ê·¹ëŒ€í™”ë¥¼ ìœ„í•œ ê³¼í•™ì  ì ‘ê·¼
â€¢ {secondary_keywords[0]}ì™€ {secondary_keywords[1] if len(secondary_keywords) > 1 else 'í¸ì˜ì„±'} ë™ì‹œ ì œê³µ
â€¢ ê°„í¸í•œ ì‚¬ìš©ë²•ìœ¼ë¡œ ëˆ„êµ¬ë‚˜ ì‰½ê²Œ ì‹œì‘
â€¢ ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™© ì¶”ì  ë° í†µê³„

ğŸ† ì™œ {app_name}ì¸ê°€ìš”?
â€¢ ê²€ì¦ëœ {primary_keyword} ë°©ë²•ë¡  ì ìš©
â€¢ ì§ê´€ì ì¸ ì¸í„°í˜ì´ìŠ¤ë¡œ ìŠ¤íŠ¸ë ˆìŠ¤ ì—†ëŠ” ì‚¬ìš©
â€¢ ì§€ì†ì ì¸ ì—…ë°ì´íŠ¸ë¡œ ì‚¬ìš©ì í”¼ë“œë°± ë°˜ì˜
â€¢ ë¬´ë£Œë¡œ ì‹œì‘í•´ì„œ í”„ë¦¬ë¯¸ì—„ìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œ ê°€ëŠ¥

ğŸ’¡ ì´ëŸ° ë¶„ë“¤ê»˜ ì¶”ì²œ:
â€¢ {primary_keyword} ê°œì„ ì´ í•„ìš”í•œ ì§ì¥ì¸/í•™ìƒ
â€¢ {secondary_keywords[0]} ë„êµ¬ë¥¼ ì°¾ëŠ” ë¶„
â€¢ ê°„ë‹¨í•˜ê³  íš¨ê³¼ì ì¸ ì†”ë£¨ì…˜ì„ ì›í•˜ëŠ” ë¶„

ğŸ“± ì§€ê¸ˆ ë°”ë¡œ ë‹¤ìš´ë¡œë“œí•˜ê³  {primary_keyword} ë§ˆìŠ¤í„°ê°€ ë˜ì–´ë³´ì„¸ìš”!

#ï¸âƒ£ {' #'.join(keywords[:5])} #ì•±ì¶”ì²œ #ë¬´ë£Œì•±"""

    return description

def create_aso_config_template(keywords: List[str], app_name: str = "New App") -> Dict:
    """ASO ë¶„ì„ ê²°ê³¼ë¥¼ ì•± ì„¤ì •ì— ì ìš©í•  ìˆ˜ ìˆëŠ” í…œí”Œë¦¿ ìƒì„±"""
    
    return {
        "marketing": {
            "aso": {
                "primary_keywords": keywords[:3],
                "secondary_keywords": keywords[3:8],
                "optimized_title_variants": [
                    app_name,
                    f"{app_name} - {keywords[0]}",
                    f"{keywords[0]} {app_name}",
                    f"{app_name} Pro",
                    f"ìµœê³ ì˜ {keywords[0]} - {app_name}"
                ],
                "keyword_density_target": {
                    keywords[0]: 3,  # ì£¼ìš” í‚¤ì›Œë“œëŠ” 3ë²ˆ ì–¸ê¸‰
                    keywords[1] if len(keywords) > 1 else "ê¸°ëŠ¥": 2,
                    keywords[2] if len(keywords) > 2 else "ì•±": 2
                },
                "competitor_analysis": {
                    "analyzed_date": datetime.now().isoformat(),
                    "top_competitors": 5,
                    "keyword_gap_analysis": True
                }
            }
        }
    }

if __name__ == "__main__":
    # ë°”ë¡œ ì‹¤í–‰ ê°€ëŠ¥í•œ í…ŒìŠ¤íŠ¸
    result, keywords = main()
    
    print(f"\nğŸ‰ MVP í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print(f"âœ… ì‹¤ì œ Play Storeì—ì„œ {len(result['competitor_apps'])}ê°œ ì•± ë¶„ì„")
    print(f"âœ… {len(result['top_keywords'])}ê°œ í‚¤ì›Œë“œ ì¶”ì¶œ ì™„ë£Œ")
    print(f"âœ… ASO ìµœì í™” í…œí”Œë¦¿ ìƒì„± ì™„ë£Œ")
    
    # ASO ì„¤ì • í…œí”Œë¦¿ ìƒì„±
    aso_template = create_aso_config_template(keywords, "Focus Timer Pro")
    
    with open('aso_template.json', 'w', encoding='utf-8') as f:
        json.dump(aso_template, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ’¾ ASO í…œí”Œë¦¿ ì €ì¥: aso_template.json")
    print(f"\nğŸš€ ë‹¤ìŒ ë‹¨ê³„: ì´ í‚¤ì›Œë“œë“¤ì„ app_config.jsonì— ì ìš©í•˜ì„¸ìš”!")
