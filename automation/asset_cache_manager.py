#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Asset Cache Manager
ë¡œì»¬ ì—ì…‹ ìºì‹±ìœ¼ë¡œ Nano Banana ë¹„ìš© 50% ì ˆê° ì‹œìŠ¤í…œ
"""

import os
import json
import hashlib
import shutil
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from datetime import datetime, timedelta
import logging

class AssetCacheManager:
    """ë¡œì»¬ ì—ì…‹ ìºì‹œ ê´€ë¦¬ì"""

    def __init__(self, cache_dir: str = None):
        self.logger = logging.getLogger(__name__)

        # ìºì‹œ ë””ë ‰í† ë¦¬ ì„¤ì •
        if cache_dir:
            self.cache_dir = Path(cache_dir)
        else:
            self.cache_dir = Path.home() / ".cache" / "app-factory" / "assets"

        self.cache_dir.mkdir(parents=True, exist_ok=True)

        # ë©”íƒ€ë°ì´í„° íŒŒì¼
        self.metadata_file = self.cache_dir / "cache_metadata.json"
        self.stats_file = self.cache_dir / "cache_stats.json"

        # ìºì‹œ ì„¤ì •
        self.cache_config = {
            "max_cache_size_mb": 500,  # ìµœëŒ€ 500MB
            "max_age_days": 90,        # 90ì¼ í›„ ë§Œë£Œ
            "cleanup_threshold": 0.8,   # 80% ì°¼ì„ ë•Œ ì •ë¦¬
            "similarity_threshold": 0.85  # 85% ìœ ì‚¬ë„ë©´ ì¬ì‚¬ìš©
        }

        # ë©”íƒ€ë°ì´í„° ë¡œë“œ
        self.metadata = self._load_metadata()
        self.stats = self._load_stats()

        self.logger.info(f"ğŸ—‚ï¸ ì—ì…‹ ìºì‹œ ì´ˆê¸°í™”: {self.cache_dir}")
        self.logger.info(f"ğŸ“Š ìºì‹œëœ ì—ì…‹: {len(self.metadata)}ê°œ")

    def _load_metadata(self) -> Dict:
        """ìºì‹œ ë©”íƒ€ë°ì´í„° ë¡œë“œ"""
        if self.metadata_file.exists():
            try:
                with open(self.metadata_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                self.logger.warning(f"ë©”íƒ€ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")

        return {
            "assets": {},
            "created": datetime.now().isoformat(),
            "last_cleanup": datetime.now().isoformat()
        }

    def _load_stats(self) -> Dict:
        """ìºì‹œ í†µê³„ ë¡œë“œ"""
        if self.stats_file.exists():
            try:
                with open(self.stats_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                self.logger.warning(f"í†µê³„ ë¡œë“œ ì‹¤íŒ¨: {e}")

        return {
            "total_requests": 0,
            "cache_hits": 0,
            "cache_misses": 0,
            "total_saved_cost": 0.0,
            "last_updated": datetime.now().isoformat()
        }

    def _save_metadata(self):
        """ë©”íƒ€ë°ì´í„° ì €ì¥"""
        try:
            self.metadata["last_updated"] = datetime.now().isoformat()
            with open(self.metadata_file, 'w', encoding='utf-8') as f:
                json.dump(self.metadata, f, indent=2, ensure_ascii=False)
        except Exception as e:
            self.logger.error(f"ë©”íƒ€ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")

    def _save_stats(self):
        """í†µê³„ ì €ì¥"""
        try:
            self.stats["last_updated"] = datetime.now().isoformat()
            with open(self.stats_file, 'w', encoding='utf-8') as f:
                json.dump(self.stats, f, indent=2, ensure_ascii=False)
        except Exception as e:
            self.logger.error(f"í†µê³„ ì €ì¥ ì‹¤íŒ¨: {e}")

    def generate_cache_key(self, prompt: str, category: str, style_params: Dict = None) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""

        # í”„ë¡¬í”„íŠ¸ ì •ê·œí™”
        normalized_prompt = self._normalize_prompt(prompt)

        # ìŠ¤íƒ€ì¼ íŒŒë¼ë¯¸í„° ì •ê·œí™”
        style_str = ""
        if style_params:
            sorted_params = sorted(style_params.items())
            style_str = json.dumps(sorted_params, sort_keys=True)

        # í‚¤ ìƒì„±ìš© ë¬¸ìì—´ êµ¬ì„±
        key_string = f"{category}|{normalized_prompt}|{style_str}"

        # SHA256 í•´ì‹œ ìƒì„±
        hash_key = hashlib.sha256(key_string.encode()).hexdigest()[:16]

        return f"{category}_{hash_key}"

    def _normalize_prompt(self, prompt: str) -> str:
        """í”„ë¡¬í”„íŠ¸ ì •ê·œí™” (ìœ ì‚¬í•œ í”„ë¡¬í”„íŠ¸ ìºì‹œ ì¬ì‚¬ìš©ì„ ìœ„í•´)"""

        # ì†Œë¬¸ì ë³€í™˜
        normalized = prompt.lower().strip()

        # ê³µí†µ ë‹¨ì–´ ì œê±°/í†µì¼
        replacements = {
            "premium": "pro",
            "professional": "pro",
            "advanced": "pro",
            "modern": "clean",
            "contemporary": "clean",
            "sleek": "clean",
            "beautiful": "elegant",
            "stunning": "elegant",
            "amazing": "elegant"
        }

        for old, new in replacements.items():
            normalized = normalized.replace(old, new)

        # ì—°ì† ê³µë°± ì œê±°
        normalized = " ".join(normalized.split())

        return normalized

    def find_similar_asset(self, cache_key: str, prompt: str, category: str) -> Optional[str]:
        """ìœ ì‚¬í•œ ì—ì…‹ ì°¾ê¸°"""

        if cache_key in self.metadata["assets"]:
            # ì •í™•í•œ í‚¤ ë§¤ì¹˜
            asset_info = self.metadata["assets"][cache_key]
            cached_file = self.cache_dir / asset_info["filename"]

            if cached_file.exists() and not self._is_expired(asset_info):
                self.logger.info(f"ğŸ¯ ìºì‹œ ì •í™• ë§¤ì¹˜: {cache_key}")
                return str(cached_file)

        # ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰
        normalized_prompt = self._normalize_prompt(prompt)

        best_match = None
        best_similarity = 0.0

        for key, asset_info in self.metadata["assets"].items():
            if asset_info["category"] != category:
                continue

            cached_file = self.cache_dir / asset_info["filename"]
            if not cached_file.exists() or self._is_expired(asset_info):
                continue

            # í”„ë¡¬í”„íŠ¸ ìœ ì‚¬ë„ ê³„ì‚°
            similarity = self._calculate_similarity(
                normalized_prompt,
                self._normalize_prompt(asset_info["original_prompt"])
            )

            if similarity > best_similarity and similarity >= self.cache_config["similarity_threshold"]:
                best_similarity = similarity
                best_match = str(cached_file)

        if best_match:
            self.logger.info(f"ğŸ” ìºì‹œ ìœ ì‚¬ ë§¤ì¹˜: {best_similarity:.2%} ìœ ì‚¬ë„")

        return best_match

    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê³„ì‚° (Jaccard ìœ ì‚¬ë„)"""

        words1 = set(text1.split())
        words2 = set(text2.split())

        if not words1 and not words2:
            return 1.0

        intersection = words1 & words2
        union = words1 | words2

        return len(intersection) / len(union) if union else 0.0

    def _is_expired(self, asset_info: Dict) -> bool:
        """ì—ì…‹ ë§Œë£Œ ì—¬ë¶€ í™•ì¸"""

        created_time = datetime.fromisoformat(asset_info["created_at"])
        expiry_time = created_time + timedelta(days=self.cache_config["max_age_days"])

        return datetime.now() > expiry_time

    def cache_asset(self, asset_data: Dict, cache_key: str, prompt: str, category: str) -> str:
        """ì—ì…‹ì„ ìºì‹œì— ì €ì¥"""

        try:
            # íŒŒì¼ëª… ìƒì„±
            filename = f"{cache_key}.png"  # ê¸°ë³¸ì ìœ¼ë¡œ PNGë¡œ ì €ì¥
            cached_file = self.cache_dir / filename

            # ì—ì…‹ ë°ì´í„°ì—ì„œ íŒŒì¼ ì €ì¥ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” URLì—ì„œ ë‹¤ìš´ë¡œë“œ)
            if "image_url" in asset_data:
                # ì‹¤ì œë¡œëŠ” URLì—ì„œ ë‹¤ìš´ë¡œë“œ
                self._download_and_save(asset_data["image_url"], cached_file)
            elif "local_path" in asset_data:
                # ë¡œì»¬ íŒŒì¼ ë³µì‚¬
                shutil.copy2(asset_data["local_path"], cached_file)
            else:
                # ì‹œë®¬ë ˆì´ì…˜: ë”ë¯¸ íŒŒì¼ ìƒì„±
                cached_file.write_text(f"Cached asset: {cache_key}")

            # ë©”íƒ€ë°ì´í„° ì €ì¥
            self.metadata["assets"][cache_key] = {
                "filename": filename,
                "category": category,
                "original_prompt": prompt,
                "normalized_prompt": self._normalize_prompt(prompt),
                "created_at": datetime.now().isoformat(),
                "access_count": 1,
                "last_accessed": datetime.now().isoformat(),
                "file_size": cached_file.stat().st_size if cached_file.exists() else 0,
                "cost_saved": 0.0
            }

            self._save_metadata()

            self.logger.info(f"ğŸ’¾ ì—ì…‹ ìºì‹œë¨: {cache_key} -> {filename}")
            return str(cached_file)

        except Exception as e:
            self.logger.error(f"ì—ì…‹ ìºì‹œ ì‹¤íŒ¨: {e}")
            return None

    def _download_and_save(self, url: str, file_path: Path):
        """URLì—ì„œ ì—ì…‹ ë‹¤ìš´ë¡œë“œ ë° ì €ì¥"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” requestsë¡œ ë‹¤ìš´ë¡œë“œ
        # ì§€ê¸ˆì€ ì‹œë®¬ë ˆì´ì…˜
        file_path.write_text(f"Downloaded from: {url}")

    def get_cached_asset(self, cache_key: str, prompt: str, category: str) -> Tuple[Optional[str], bool]:
        """ìºì‹œëœ ì—ì…‹ ê°€ì ¸ì˜¤ê¸°"""

        self.stats["total_requests"] += 1

        # ìºì‹œ ê²€ìƒ‰
        cached_file = self.find_similar_asset(cache_key, prompt, category)

        if cached_file:
            # ìºì‹œ íˆíŠ¸
            self.stats["cache_hits"] += 1
            self.stats["total_saved_cost"] += 0.039  # Nano Banana ë¹„ìš© ì ˆì•½

            # ì ‘ê·¼ ê¸°ë¡ ì—…ë°ì´íŠ¸
            if cache_key in self.metadata["assets"]:
                self.metadata["assets"][cache_key]["access_count"] += 1
                self.metadata["assets"][cache_key]["last_accessed"] = datetime.now().isoformat()
                self.metadata["assets"][cache_key]["cost_saved"] += 0.039

            self._save_metadata()
            self._save_stats()

            self.logger.info(f"ğŸ¯ ìºì‹œ íˆíŠ¸! ${0.039:.3f} ì ˆì•½")
            return cached_file, True
        else:
            # ìºì‹œ ë¯¸ìŠ¤
            self.stats["cache_misses"] += 1
            self._save_stats()

            self.logger.info(f"âŒ ìºì‹œ ë¯¸ìŠ¤ - ìƒˆ ì—ì…‹ ìƒì„± í•„ìš”")
            return None, False

    def cleanup_cache(self, force: bool = False):
        """ìºì‹œ ì •ë¦¬"""

        current_size = self._get_cache_size_mb()
        max_size = self.cache_config["max_cache_size_mb"]

        if not force and current_size < max_size * self.cache_config["cleanup_threshold"]:
            return  # ì •ë¦¬ ë¶ˆí•„ìš”

        self.logger.info(f"ğŸ§¹ ìºì‹œ ì •ë¦¬ ì‹œì‘: {current_size:.1f}MB / {max_size}MB")

        # ì •ë¦¬ ëŒ€ìƒ ì„ ì • (ì˜¤ë˜ë˜ê³  ì ê²Œ ì‚¬ìš©ëœ ê²ƒë¶€í„°)
        assets_to_remove = []

        for cache_key, asset_info in self.metadata["assets"].items():
            cached_file = self.cache_dir / asset_info["filename"]

            # ë§Œë£Œëœ íŒŒì¼
            if self._is_expired(asset_info):
                assets_to_remove.append((cache_key, cached_file, "expired"))
                continue

            # íŒŒì¼ì´ ì‹¤ì œë¡œ ì¡´ì¬í•˜ì§€ ì•ŠìŒ
            if not cached_file.exists():
                assets_to_remove.append((cache_key, cached_file, "missing"))
                continue

        # ì˜¤ë˜ëœ/ì ê²Œ ì‚¬ìš©ëœ íŒŒì¼ (ìš©ëŸ‰ì´ ì—¬ì „íˆ í´ ë•Œ)
        if current_size > max_size * 0.5:  # 50% ì´ìƒì¼ ë•Œ ì¶”ê°€ ì •ë¦¬
            sorted_assets = sorted(
                self.metadata["assets"].items(),
                key=lambda x: (x[1]["access_count"], x[1]["last_accessed"])
            )

            # í•˜ìœ„ 30% ì œê±°
            remove_count = max(1, len(sorted_assets) // 3)
            for i in range(remove_count):
                cache_key, asset_info = sorted_assets[i]
                cached_file = self.cache_dir / asset_info["filename"]
                assets_to_remove.append((cache_key, cached_file, "low_usage"))

        # ì‹¤ì œ íŒŒì¼ ì‚­ì œ
        removed_count = 0
        freed_space = 0

        for cache_key, cached_file, reason in assets_to_remove:
            try:
                if cached_file.exists():
                    file_size = cached_file.stat().st_size
                    cached_file.unlink()
                    freed_space += file_size

                del self.metadata["assets"][cache_key]
                removed_count += 1

            except Exception as e:
                self.logger.warning(f"íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨ {cached_file}: {e}")

        # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
        self.metadata["last_cleanup"] = datetime.now().isoformat()
        self._save_metadata()

        new_size = self._get_cache_size_mb()
        self.logger.info(f"âœ… ìºì‹œ ì •ë¦¬ ì™„ë£Œ: {removed_count}ê°œ íŒŒì¼, {freed_space/1024/1024:.1f}MB í™•ë³´")
        self.logger.info(f"ğŸ“Š ì •ë¦¬ í›„ í¬ê¸°: {new_size:.1f}MB / {max_size}MB")

    def _get_cache_size_mb(self) -> float:
        """ìºì‹œ ë””ë ‰í† ë¦¬ í¬ê¸° ê³„ì‚° (MB)"""
        total_size = 0

        for file_path in self.cache_dir.rglob("*"):
            if file_path.is_file():
                total_size += file_path.stat().st_size

        return total_size / 1024 / 1024

    def get_cache_stats(self) -> Dict:
        """ìºì‹œ í†µê³„ ì¡°íšŒ"""

        total_requests = self.stats["total_requests"]
        hit_rate = (self.stats["cache_hits"] / total_requests * 100) if total_requests > 0 else 0

        cache_size = self._get_cache_size_mb()
        asset_count = len(self.metadata["assets"])

        return {
            "cache_performance": {
                "total_requests": total_requests,
                "cache_hits": self.stats["cache_hits"],
                "cache_misses": self.stats["cache_misses"],
                "hit_rate": f"{hit_rate:.1f}%",
                "total_cost_saved": f"${self.stats['total_saved_cost']:.2f}"
            },
            "cache_storage": {
                "total_assets": asset_count,
                "cache_size_mb": f"{cache_size:.1f}MB",
                "max_size_mb": f"{self.cache_config['max_cache_size_mb']}MB",
                "usage_percentage": f"{(cache_size / self.cache_config['max_cache_size_mb'] * 100):.1f}%"
            },
            "cache_health": {
                "last_cleanup": self.metadata.get("last_cleanup", "Never"),
                "expired_assets": self._count_expired_assets(),
                "missing_files": self._count_missing_files()
            }
        }

    def _count_expired_assets(self) -> int:
        """ë§Œë£Œëœ ì—ì…‹ ìˆ˜ ê³„ì‚°"""
        count = 0
        for asset_info in self.metadata["assets"].values():
            if self._is_expired(asset_info):
                count += 1
        return count

    def _count_missing_files(self) -> int:
        """ì‹¤ì œ íŒŒì¼ì´ ì—†ëŠ” ì—ì…‹ ìˆ˜ ê³„ì‚°"""
        count = 0
        for asset_info in self.metadata["assets"].values():
            cached_file = self.cache_dir / asset_info["filename"]
            if not cached_file.exists():
                count += 1
        return count

    def generate_cache_report(self) -> str:
        """ìºì‹œ ë¦¬í¬íŠ¸ ìƒì„±"""

        stats = self.get_cache_stats()

        report = f"""
ğŸ’¾ ì—ì…‹ ìºì‹œ ë¦¬í¬íŠ¸
{'='*50}

ğŸ“Š ì„±ëŠ¥ í†µê³„:
  ì´ ìš”ì²­ ìˆ˜: {stats['cache_performance']['total_requests']}
  ìºì‹œ íˆíŠ¸: {stats['cache_performance']['cache_hits']}
  ìºì‹œ ë¯¸ìŠ¤: {stats['cache_performance']['cache_misses']}
  íˆíŠ¸ìœ¨: {stats['cache_performance']['hit_rate']}
  ì ˆì•½ëœ ë¹„ìš©: {stats['cache_performance']['total_cost_saved']}

ğŸ’½ ì €ì¥ì†Œ í˜„í™©:
  ìºì‹œëœ ì—ì…‹: {stats['cache_storage']['total_assets']}ê°œ
  ì‚¬ìš© ìš©ëŸ‰: {stats['cache_storage']['cache_size_mb']} / {stats['cache_storage']['max_size_mb']}
  ì‚¬ìš©ë¥ : {stats['cache_storage']['usage_percentage']}

ğŸ”§ ìºì‹œ ìƒíƒœ:
  ë§ˆì§€ë§‰ ì •ë¦¬: {stats['cache_health']['last_cleanup']}
  ë§Œë£Œëœ ì—ì…‹: {stats['cache_health']['expired_assets']}ê°œ
  ëˆ„ë½ëœ íŒŒì¼: {stats['cache_health']['missing_files']}ê°œ

ğŸ’¡ ì˜ˆìƒ íš¨ê³¼:
  ì›”ê°„ ì ˆì•½ (50% íˆíŠ¸ìœ¨): $4.38
  ì—°ê°„ ì ˆì•½ (50% íˆíŠ¸ìœ¨): $52.56
"""

        return report

def main():
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""

    # ìºì‹œ ë§¤ë‹ˆì € ì´ˆê¸°í™”
    cache_manager = AssetCacheManager()

    print("ğŸ’¾ ì—ì…‹ ìºì‹œ ë§¤ë‹ˆì € í…ŒìŠ¤íŠ¸")
    print("=" * 50)

    # í…ŒìŠ¤íŠ¸ ì—ì…‹ë“¤
    test_assets = [
        {
            "prompt": "Modern fitness app icon with blue gradient",
            "category": "app_icons",
            "style": {"color": "blue", "style": "modern"}
        },
        {
            "prompt": "Premium fitness application icon with clean blue design",
            "category": "app_icons",
            "style": {"color": "blue", "style": "clean"}
        },
        {
            "prompt": "Workout tracking app screenshot with dashboard",
            "category": "screenshots",
            "style": {"type": "dashboard", "theme": "light"}
        }
    ]

    # ìºì‹œ í…ŒìŠ¤íŠ¸
    for i, asset in enumerate(test_assets):
        print(f"\nğŸ§ª í…ŒìŠ¤íŠ¸ {i+1}: {asset['prompt'][:50]}...")

        # ìºì‹œ í‚¤ ìƒì„±
        cache_key = cache_manager.generate_cache_key(
            asset["prompt"],
            asset["category"],
            asset.get("style")
        )

        # ìºì‹œì—ì„œ ì°¾ê¸°
        cached_file, is_hit = cache_manager.get_cached_asset(
            cache_key,
            asset["prompt"],
            asset["category"]
        )

        if not is_hit:
            # ìƒˆ ì—ì…‹ ìƒì„± ì‹œë®¬ë ˆì´ì…˜
            print(f"  ğŸ¨ ìƒˆ ì—ì…‹ ìƒì„± ì¤‘...")

            fake_asset_data = {
                "image_url": f"https://fake-nano-banana.com/{cache_key}.png",
                "cost": 0.039
            }

            # ìºì‹œì— ì €ì¥
            cache_manager.cache_asset(
                fake_asset_data,
                cache_key,
                asset["prompt"],
                asset["category"]
            )

    # ìµœì¢… ë¦¬í¬íŠ¸
    print(cache_manager.generate_cache_report())

    # ìºì‹œ ì •ë¦¬ í…ŒìŠ¤íŠ¸
    print("\nğŸ§¹ ìºì‹œ ì •ë¦¬ í…ŒìŠ¤íŠ¸...")
    cache_manager.cleanup_cache(force=True)

if __name__ == "__main__":
    main()